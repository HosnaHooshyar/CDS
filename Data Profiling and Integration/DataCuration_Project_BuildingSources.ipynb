{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "# from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "import ast\n",
    "from ast import literal_eval\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerCase(df):\n",
    "    '''\n",
    "    This function changes the names of column and the columns values that are string, into lowercase\n",
    "    '''\n",
    "    # converts the name of columns to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # converts the string values of columns to lowercase\n",
    "    for column in list(df.columns):\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = df[column].map(\n",
    "                lambda x: x.lower() if isinstance(x, str) else x)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(df):\n",
    "    '''\n",
    "    This function removes the white space at the beginning and end of string values\n",
    "    '''\n",
    "    for c in df.columns:\n",
    "        # it is only applied to columns of the type object\n",
    "        if df[c].dtype == 'object':\n",
    "            df[c] = df[c].str.strip()\n",
    "            df[c] = df[c].str.strip('-')\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ID(df, cList, cName, idName):\n",
    "    df2 = df[cList]\n",
    "    df2 = df2.dropna(how='all')\n",
    "    df2 = df2.drop_duplicates(keep='last').reset_index()\n",
    "    df2 = df2.drop(labels='index', axis=1)\n",
    "\n",
    "    df2[cName] = df2.index + 1\n",
    "    df2[cName] = df2[cName].astype(str)\n",
    "    df2[cName] = idName + df2[cName]\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(column,df):\n",
    "    '''\n",
    "    This function removes the duplicated columns based on the number of null values\n",
    "        e.g. between genre_x and genre_y, the one that has less null values will be removed\n",
    "    column: A list of columns\n",
    "    '''\n",
    "\n",
    "    # Duplicated columns are used to fill the null values of each other\n",
    "    # e.g. genre_x is used to fill null values of genre_y and vise versa\n",
    "    for c in column:\n",
    "        x = c + '_x'\n",
    "        y = c + '_y'\n",
    "        if x in list(df.columns):\n",
    "            df[x] = df[x].fillna(df[y])\n",
    "            df[y] = df[y].fillna(df[x])\n",
    "\n",
    "    # Between duplicated columns, the one with more null values will be removed\n",
    "    for c in column:\n",
    "        x = c + '_x'\n",
    "        y = c + '_y'\n",
    "        if x in list(df.columns):\n",
    "            if df[x].isna().sum() <= df[y].isna().sum():\n",
    "                df = df.drop(labels=y, axis=1)\n",
    "                df.rename(columns={x:c}, inplace=True)\n",
    "            else:\n",
    "                df = df.drop(labels=x, axis=1)\n",
    "                df.rename(columns={y:c}, inplace=True)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data which is the result of preprocessing is imported here so we can do some additional operations such as combining tables and adding IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_1 = pd.read_csv('./data/final_anime_1.csv')\n",
    "final_anime_2 = pd.read_csv('./data/final_anime_2.csv')\n",
    "final_anime_3 = pd.read_csv('./data/final_anime_3.csv')\n",
    "final_anime_4 = pd.read_csv('./data/final_anime_4.csv')\n",
    "final_anime_5 = pd.read_csv('./data/final_anime_5.csv')\n",
    "final_profile = pd.read_csv('./data/final_profile.csv')\n",
    "final_review = pd.read_csv('./data/final_review.csv')\n",
    "final_watching_status = pd.read_csv('./data/final_watching_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFs = [final_anime_1, final_anime_2, final_anime_3, final_anime_4, final_anime_5, final_profile,\n",
    "       final_review, final_watching_status]\n",
    "\n",
    "for df in DFs:\n",
    "    #df = strip(df)\n",
    "    df = lowerCase(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source 1: Anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_1 = final_anime_1.drop(labels=['ranked','popularity'], axis=1)\n",
    "final_anime_1.rename(columns={'title': 'Name', 'uid':'anime1_ID'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_2 = final_anime_2.drop(labels=['ranked', 'popularity', 'score-10', 'score-9', 'score-8',\n",
    "                                           'score-7', 'score-6', 'score-5', 'score-4', 'score-3',\n",
    "                                           'score-2', 'score-1'], axis=1)\n",
    "\n",
    "final_anime_2.rename(\n",
    "    columns={'name': 'Name', 'mal_id': 'anime2_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = list(set(final_anime_1.columns).intersection(final_anime_2.columns))\n",
    "\n",
    "# Creating the anime table\n",
    "anime = final_anime_1.merge(final_anime_2, on=['Name'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = remove(Columns, anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_3.rename(columns={'name':'Name','mal_id':'anime3_id'},inplace=True)\n",
    "final_anime_3 = final_anime_3.drop_duplicates(subset=['Name'], keep='first')\n",
    "\n",
    "Columns = list(set(final_anime_3.columns).intersection(anime.columns))\n",
    "anime = anime.merge(final_anime_3, on='Name', how='outer')\n",
    "anime = remove(Columns, anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_4 = final_anime_4.drop(labels=['score rank', 'popularity rank', 'air date', 'theme1',\n",
    "                                           'theme2', 'theme3', 'theme4', 'theme5'], axis=1)\n",
    "final_anime_4.rename(\n",
    "    columns={'name': 'Name', 'num. of episodes': 'episodes',\n",
    "             'demographic': 'demographic1'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = list(set(final_anime_4.columns).intersection(anime.columns))\n",
    "anime = anime.merge(final_anime_4, on='Name', how='outer')\n",
    "anime = remove(Columns, anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_5 = final_anime_5.drop(labels=['rank', 'minutes'], axis=1)\n",
    "final_anime_5.rename(\n",
    "    columns={'title': 'Name', 'rating':'score','year':'first_aired',}, inplace=True)\n",
    "\n",
    "Columns = list(set(final_anime_5.columns).intersection(anime.columns))\n",
    "anime = anime.merge(final_anime_5, on='Name', how='outer')\n",
    "anime = remove(Columns, anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "incase = anime.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['animeID'] = anime.index + 1\n",
    "anime['animeID'] = anime['animeID'].astype(str)\n",
    "anime['animeID'] = 'anime_' + anime['animeID'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_res = create_ID(anime,['age_restriction','meaning'],'ageID','age_')\n",
    "anime = anime.merge(age_res, on=['age_restriction','meaning'],how='outer')\n",
    "incase.shape[0] == anime.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime['studio1'] = anime['studio1'].replace({'unknown': None})\n",
    "anime['studio1'] = anime['studio1'].replace({'none': None})\n",
    "studio = create_ID(anime, ['studio1'], 'studioID', 'st_')\n",
    "anime = anime.merge(studio, on=['studio1'], how='outer')\n",
    "incase.shape[0] == anime.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951680905358926"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(anime['demographic2'].isna().sum())/anime.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the column *demographic2* is empty, as a result we ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = create_ID(anime,['demographic1'],'demoID','De_')\n",
    "anime = anime.merge(demo, on=['demographic1'],how='outer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = create_ID(anime,['link','img_url'],'linkID','url_')\n",
    "anime = anime.merge(links, on=['link','img_url'], how='outer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_list = ['members', 'score', 'completed', 'dropped',\n",
    "                   'favorites', 'on-hold', 'plan to watch', 'watching']\n",
    "\n",
    "popularity = create_ID(anime, popularity_list, 'popularityID', 'Po_')\n",
    "Ws_list = ['completed','dropped','on-hold','plan to watch','watching']\n",
    "watching_status = create_ID(popularity, Ws_list,'wsID','WS_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity = popularity.merge(watching_status, on=Ws_list, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = anime.merge(popularity, on=popularity_list, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity = popularity[['popularityID','members','score','wsID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_anime_5['TopIMDb'] = True\n",
    "imdb = final_anime_5[['Name', 'TopIMDb']]\n",
    "anime = anime.merge(imdb, on='Name', how='outer')\n",
    "anime['TopIMDb'] = anime['TopIMDb'].fillna(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gList = ['genre1', 'genre2', 'genre3']\n",
    "genre = create_ID(anime, gList, 'genreID', 'Ge_')\n",
    "anime = anime.merge(genre, on=gList, how='outer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Review = final_review.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Review['reviewID'] = Review.index + 1\n",
    "Review['reviewID'] = Review['reviewID'].astype(str)\n",
    "Review['reviewID'] = 'rev_' + Review['reviewID'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Review.to_csv('review_source.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = anime[['anime1_ID', 'animeID', 'linkID']]\n",
    "a.rename(columns={'anime1_ID': 'anime_uid'}, inplace=True)\n",
    "Review = Review.merge(a, on='anime_uid')\n",
    "Review.rename(columns={'link': 'review_link'}, inplace=True)\n",
    "Review = Review[['reviewID', 'profile', 'review_link', 'overall', 'linkID']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_profile['BD_year'] = pd.DatetimeIndex(final_profile['birthday']).year\n",
    "final_profile['BD_month'] = pd.DatetimeIndex(final_profile['birthday']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = set(final_review['profile'].unique()) - set(final_profile['profile'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All writers of review need to be in profile\n",
    "for diff in difference:\n",
    "    new_row = {'profile':diff}\n",
    "    final_profile = final_profile.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_profile.to_csv('final_profile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviewer = final_profile.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rlist = ['profile', 'gender', 'birthday', 'favanime1',\n",
    "         'favanime2', 'favanime3', 'favanime4', 'favanime5']\n",
    "Reviewer = create_ID(Reviewer, Rlist, 'ReviewerID', 'Reviewer_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviewer.to_csv('Reviewer.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['year'] = pd.DatetimeIndex(anime['first_aired']).year\n",
    "anime['month'] = pd.DatetimeIndex(anime['first_aired']).month\n",
    "date = create_ID(anime,['year','month'],'dateID','date_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviewer['year'] = pd.DatetimeIndex(Reviewer['birthday']).year\n",
    "Reviewer['month'] = pd.DatetimeIndex(Reviewer['birthday']).month\n",
    "\n",
    "dateR = create_ID(Reviewer, ['year', 'month'], 'dateID', 'date_')\n",
    "dateR['year'] = dateR['year'].astype(int)\n",
    "dateR['month'] = dateR['month'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = date.merge(dateR, on=['year','month'],how='outer')\n",
    "date['year'] = date['year'].astype(int)\n",
    "date['month'] = date['month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = date.sort_values(['year','month']).reset_index()\n",
    "date = date.drop(labels=['index','dateID_x','dateID_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "date['dateID'] = date.index + 1\n",
    "date['dateID'] = date['dateID'].astype(str)\n",
    "date['dateID'] = 'date_' + date['dateID'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.to_csv('date_source.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['score'] = anime['score'].replace({'unknown': np.nan})\n",
    "anime['score'] = anime['score'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(anime.columns):\n",
    "    if anime[c].dtype == 'object':\n",
    "        anime[c] = anime[c].replace({'unknown': None})\n",
    "        anime[c] = anime[c].replace({'none': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime.to_csv('anime_source.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataProfiling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1af63472e87732c8c44e028c6c515f53204d998e83d5ec012bb8a3c22f8f5120"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
